帮我编写 Menu.ai (What to eat today) 的后端项目，使用 Python 和 LangChain。用于处理前端树莓派传入的数据。

1. 包含录入菜品模块。摄像头录入食堂今天的菜品，通过 AI 大模型接口（如 zhipu glm-4.5v），像 Cal AI 一样，分析它的成分、热量、辣度等营养成分，保存到数据库。
2. 另一个是推荐模块，根据用户的需求，为用户推荐今天吃什么。分访客模式和用户模式，我们先完成访客模式，但也要预留用户模式（例如使用RFID或者人脸识别进行登录等）。将用户输入（树莓派语音输入）、用户习惯（访客模式暂无）、传感器的信息（温度、湿度等）输入到大语言模型，然后输出菜品列表。菜品列表可以更换刷新，也可以根据用户的进一步需求再进行改进。

请完成如下功能：
1. 录入菜品模块
    - GLM-4.5V 是智谱新一代基于 MOE 架构的视觉推理模型，以 106B 的总参数量和 12B 激活参数量，在各类基准测试中达到全球同级别开源多模态模型 SOTA，涵盖图像、视频、文档理解及 GUI 任务等常见任务。https://docs.bigmodel.cn/cn/guide/models/vlm/glm-4.5v
    - 批量录入：例如，一张照片（食堂的自助餐台）包含 12 个菜品，每个菜品的照片都被自动分析并录入数据库。
    - 单个录入：用户可以上传一个菜品的照片，系统自动分析并录入数据库。
    - 手动录入：管理员可以手动输入每个菜品的信息，包括名称、成分、热量、辣度等。
2. 推荐模块（访客模式）
    - 前端：用户输入需求（例如：“我刚切除肠内息肉，请为我推荐两道菜。”）。
    - 后端：接收用户输入，调用 AI 大模型接口分析用户需求，根据数据库中的菜品信息进行推荐。
3. 语音录入
    - 前端：用户通过树莓派的麦克风录入语音。
    - CogTTS 语音合成模型：以新一代智谱语音大模型为核心，突破传统语音合成框架，通过上下文智能预判文本情绪与语调，显著提升语音自然度与表现力，让合成语音具备真实情感与生命力。https://docs.bigmodel.cn/cn/guide/models/sound-and-video/cogtts