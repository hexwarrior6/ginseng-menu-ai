#!/usr/bin/env python3
import pyaudio
import json
from vosk import Model, KaldiRecognizer
import time

# å…¨å±€é…ç½®
RATE = 16000
CHUNK = 8000
MODEL_PATH = "/home/ginseng/myprograms/ginseng-menu-ai/local_models/vosk-model-small-en-us-0.15"

# å…¨å±€æ¨¡å‹å®ä¾‹ï¼ˆé¿å…é‡å¤åŠ è½½ï¼‰
_model = None
_recognizer = None

def init_recognizer():
    """åˆå§‹åŒ–è¯†åˆ«å™¨ï¼ˆåªéœ€è°ƒç”¨ä¸€æ¬¡ï¼‰"""
    global _model, _recognizer
    if _model is None:
        print("æ­£åœ¨åŠ è½½è¯­éŸ³è¯†åˆ«æ¨¡å‹...")
        _model = Model(MODEL_PATH)
        _recognizer = KaldiRecognizer(_model, RATE)
        _recognizer.SetWords(True)
        print("æ¨¡å‹åŠ è½½å®Œæˆï¼")
    return _recognizer

def recognize_speech(timeout=10, device_index=None, silence_threshold=1.5, 
                     on_partial=None, on_final=None):
    """
    å½•éŸ³å¹¶è¯†åˆ«è¯­éŸ³ï¼Œè¿”å›è¯†åˆ«ç»“æœ
    
    å‚æ•°:
        timeout: æœ€å¤§å½•éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤10ç§’
        device_index: éŸ³é¢‘è®¾å¤‡ç´¢å¼•ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨é»˜è®¤è®¾å¤‡
        silence_threshold: é™éŸ³åˆ¤æ–­æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œè¿ç»­é™éŸ³è¶…è¿‡æ­¤æ—¶é—´åˆ™åœæ­¢å½•éŸ³
        on_partial: å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶å®æ—¶çš„éƒ¨åˆ†è¯†åˆ«ç»“æœ (text: str) -> None
        on_final: å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶å®Œæ•´å¥å­çš„è¯†åˆ«ç»“æœ (text: str) -> None
    
    è¿”å›:
        str: è¯†åˆ«åˆ°çš„æ–‡æœ¬ï¼Œå¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
    """
    # ç¡®ä¿æ¨¡å‹å·²åŠ è½½
    recognizer = init_recognizer()
    recognizer.Reset()  # é‡ç½®è¯†åˆ«å™¨çŠ¶æ€
    
    p = pyaudio.PyAudio()
    
    try:
        # æ‰“å¼€éŸ³é¢‘æµ
        stream = p.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=RATE,
            input=True,
            input_device_index=device_index,
            frames_per_buffer=CHUNK
        )
        
        print("ğŸ¤ å¼€å§‹å½•éŸ³... (è¯·è¯´è¯)")
        stream.start_stream()
        
        start_time = time.time()
        last_sound_time = time.time()
        recognized_text = ""
        
        while True:
            # æ£€æŸ¥è¶…æ—¶
            if time.time() - start_time > timeout:
                print("\nâ±ï¸  å½•éŸ³è¶…æ—¶")
                break
            
            # è¯»å–éŸ³é¢‘æ•°æ®
            data = stream.read(CHUNK, exception_on_overflow=False)
            
            # è®¡ç®—éŸ³é‡
            volume = max(abs(int.from_bytes(data[i:i+2], 'little', signed=True)) 
                        for i in range(0, len(data), 2))
            
            # æ˜¾ç¤ºéŸ³é‡æŒ‡ç¤º
            if volume > 1000:
                print(f"ğŸ”Š éŸ³é‡: {volume}  ", end='\r')
                last_sound_time = time.time()
            
            # è¯†åˆ«éŸ³é¢‘
            if recognizer.AcceptWaveform(data):
                # å®Œæ•´å¥å­è¯†åˆ«
                result = json.loads(recognizer.Result())
                text = result.get('text', '').strip()
                if text:
                    recognized_text = text
                    print(f"\nâœ“ è¯†åˆ«åˆ°: {text}")
                    last_sound_time = time.time()
                    # è°ƒç”¨å®Œæ•´ç»“æœå›è°ƒ
                    if on_final:
                        on_final(text)
            else:
                # éƒ¨åˆ†è¯†åˆ«ç»“æœ
                partial = json.loads(recognizer.PartialResult())
                text = partial.get('partial', '').strip()
                if text:
                    print(f"[å®æ—¶] {text}        ", end='\r')
                    # è°ƒç”¨éƒ¨åˆ†ç»“æœå›è°ƒ
                    if on_partial:
                        on_partial(text)
            
            # æ£€æŸ¥é™éŸ³æ—¶é•¿ï¼ˆå¦‚æœå·²ç»è¯†åˆ«åˆ°å†…å®¹ï¼‰
            if recognized_text and time.time() - last_sound_time > silence_threshold:
                print("\nğŸ”‡ æ£€æµ‹åˆ°é™éŸ³ï¼Œç»“æŸå½•éŸ³")
                break
        
        # è·å–æœ€ç»ˆç»“æœ
        final_result = json.loads(recognizer.FinalResult())
        final_text = final_result.get('text', '').strip()
        if final_text and not recognized_text:
            recognized_text = final_text
            print(f"âœ“ æœ€ç»ˆè¯†åˆ«: {final_text}")
        
        stream.stop_stream()
        stream.close()
        
        return recognized_text
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        return ""
    finally:
        p.terminate()

def recognize_speech_continuous(callback, device_index=None, stop_callback=None):
    """
    æŒç»­è¯†åˆ«è¯­éŸ³å¹¶é€šè¿‡å›è°ƒå‡½æ•°è¿”å›ç»“æœ
    
    å‚æ•°:
        callback: å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶è¯†åˆ«åˆ°çš„æ–‡æœ¬ä½œä¸ºå‚æ•°
        device_index: éŸ³é¢‘è®¾å¤‡ç´¢å¼•
        stop_callback: è¿”å›Trueæ—¶åœæ­¢è¯†åˆ«çš„å‡½æ•°
    """
    recognizer = init_recognizer()
    recognizer.Reset()
    
    p = pyaudio.PyAudio()
    
    try:
        stream = p.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=RATE,
            input=True,
            input_device_index=device_index,
            frames_per_buffer=CHUNK
        )
        
        print("ğŸ¤ å¼€å§‹æŒç»­ç›‘å¬... (æŒ‰Ctrl+Cåœæ­¢)")
        stream.start_stream()
        
        while True:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
            if stop_callback and stop_callback():
                break
            
            data = stream.read(CHUNK, exception_on_overflow=False)
            
            if recognizer.AcceptWaveform(data):
                result = json.loads(recognizer.Result())
                text = result.get('text', '').strip()
                if text:
                    callback(text)
            else:
                partial = json.loads(recognizer.PartialResult())
                text = partial.get('partial', '').strip()
                if text:
                    print(f"[å®æ—¶] {text}        ", end='\r')
        
        stream.stop_stream()
        stream.close()
        
    except KeyboardInterrupt:
        print("\n\nåœæ­¢è¯†åˆ«")
    finally:
        p.terminate()


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    # æ–¹å¼1: å•æ¬¡è¯†åˆ«ï¼ˆä¸ä½¿ç”¨å›è°ƒï¼‰
    print("=== æ–¹å¼1: ç®€å•ç”¨æ³• ===")
    result = recognize_speech(timeout=10, silence_threshold=2.0)
    if result:
        print(f"\næœ€ç»ˆç»“æœ: '{result}'")
    else:
        print("\næœªè¯†åˆ«åˆ°è¯­éŸ³")
    
    # æ–¹å¼2: ä½¿ç”¨å›è°ƒè·å–æµå¼ç»“æœ
    print("\n=== æ–¹å¼2: æµå¼è¯†åˆ«ï¼ˆå¸¦å›è°ƒï¼‰===")
    
    def on_partial_result(text):
        """å®æ—¶éƒ¨åˆ†ç»“æœå›è°ƒ"""
        print(f"\r[æµå¼] {text}                    ", end='')
    
    def on_final_result(text):
        """å®Œæ•´å¥å­ç»“æœå›è°ƒ"""
        print(f"\n[å®Œæˆ] {text}")
    
    result = recognize_speech(
        timeout=10,
        silence_threshold=2.0,
        on_partial=on_partial_result,
        on_final=on_final_result
    )
    print(f"\næœ€ç»ˆè¿”å›: '{result}'")
    
    # æ–¹å¼3: æŒç»­è¯†åˆ«
    # print("\n=== æ–¹å¼3: æŒç»­è¯†åˆ« ===")
    # def on_speech(text):
    #     print(f"\nè¯†åˆ«åˆ°: {text}")
    # 
    # recognize_speech_continuous(on_speech)